{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4dfb7f-701b-4ed8-b17a-df4789dad704",
   "metadata": {},
   "source": [
    "# CNN Text Classification\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) for sentence classification using the IMDb dataset. The model uses Word2Vec embeddings and PyTorch for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e330ab3-ea11-4c8b-bd9e-366035ecd48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch for building the CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.functional as F\n",
    "\n",
    "# NLP libraries for text processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Embeddings (optional, for loading pre-trained ones like GloVe)\n",
    "import gensim\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Kaggle API for dataset\n",
    "import kaggle\n",
    "\n",
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Jupyter notebook-specific libraries\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9397a56f-49be-4ea5-9656-9cd4374d0575",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "In this section, we load the IMDb dataset and perform text preprocessing, including tokenization, stopword removal, and padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25ad64ab-d0d2-4e15-b360-5ea2e65541f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98d6dd80-d90a-4a8d-8457-60e7aa8e9fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will be using the IMDB movies review dataset from kaggle\n",
    "df = pd.read_csv('imdb-data/IMDB Dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a23b3c76-ed60-40b9-bb6b-3945f85443af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kalindadhikari/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/kalindadhikari/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kalindadhikari/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I am going to download NLTK resources \n",
    "\n",
    "# The punkt will vectorize words, encapsulating meaning within the sentence.\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "# The stopwords will be used to vectorize things such as 'the' or 'and' which don't really contribute to the meaning directly.\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a83f2bf7-024f-4bdd-8b21-27d24a51dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the stopwords in english\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Makes all the text lower, so that captial letters don't have a different meaning from lowercase.\n",
    "    text = text.lower()\n",
    "    # Tokenizes the text into a vector.\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removes the stop words from the tokens, as we said earlier, it does not effect the sentence\n",
    "    # Ex: 'I love this movie', is the same as 'love movie' for our classification task. \n",
    "    tokens = [word for word in tokens if word.isalpha() not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1dabf68-2aa6-490c-b032-42cbacd19617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e76ba0d7-d566-433d-bb61-2ec886970ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# The CNN cannot directly work with textual data, so we need to assign an index to each word.\n",
    "\n",
    "# Here we have a vocab dictionary that will automatically do this for us.\n",
    "vocab = defaultdict(lambda: len(vocab))\n",
    "vocab['<PAD>'] = 0     # padding used to pad shorters sentences to match longer ones. ('loved movie <pad>') ('loved movie greatly').\n",
    "vocab['<UNK>'] = 1     # unknown used to map words that may be unknown to our vocabulary either during testing or training.\n",
    "\n",
    "# Loading the tokens (each word) into the vocab\n",
    "for tokens in df['tokens']:\n",
    "    for token in tokens:\n",
    "        vocab[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "478d4773-58a1-4e49-880e-9a147daa3935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[a, wonderful, little, production, ., &lt;, br, /...</td>\n",
       "      <td>[57, 204, 205, 206, 20, 33, 34, 35, 36, 33, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "      <td>[128, 289, 26, 42, 57, 204, 290, 68, 291, 292,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, there, 's, a, family, where, a, li...</td>\n",
       "      <td>[366, 367, 254, 57, 368, 93, 57, 205, 369, 166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, 's, ``, love, in, the, time, ...</td>\n",
       "      <td>[417, 418, 254, 227, 419, 51, 4, 292, 3, 420, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [one, of, the, other, reviewers, has, mentione...   \n",
       "1  [a, wonderful, little, production, ., <, br, /...   \n",
       "2  [i, thought, this, was, a, wonderful, way, to,...   \n",
       "3  [basically, there, 's, a, family, where, a, li...   \n",
       "4  [petter, mattei, 's, ``, love, in, the, time, ...   \n",
       "\n",
       "                                             indices  \n",
       "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
       "1  [57, 204, 205, 206, 20, 33, 34, 35, 36, 33, 34...  \n",
       "2  [128, 289, 26, 42, 57, 204, 290, 68, 291, 292,...  \n",
       "3  [366, 367, 254, 57, 368, 93, 57, 205, 369, 166...  \n",
       "4  [417, 418, 254, 227, 419, 51, 4, 292, 3, 420, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokens_to_indicies(tokens, vocab):\n",
    "    new_list = []\n",
    "    for token in tokens:\n",
    "        new_list.append(vocab.get(token, vocab['<UNK>']))\n",
    "\n",
    "    return new_list\n",
    "\n",
    "df['indices'] = df['tokens'].apply(lambda x: tokens_to_indicies(x, vocab))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04c8160d-b69c-48fa-ae59-531f643e0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to PAD the input statements (or truncate if too small)\n",
    "MAX_LEN = 100    # According to what was used in the paper\n",
    "\n",
    "def pad_sequence(seq, max_len):\n",
    "    if len(seq) < max_len:\n",
    "        return seq + [vocab['<PAD>']] * (max_len - len(seq))\n",
    "    else:\n",
    "        return seq[:max_len]\n",
    "\n",
    "df['padded_indices'] = df['indices'].apply(lambda x: pad_sequence(x, MAX_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76b04e1c-8f38-47e5-848b-d9654dbc5a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>indices</th>\n",
       "      <th>padded_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[a, wonderful, little, production, ., &lt;, br, /...</td>\n",
       "      <td>[57, 204, 205, 206, 20, 33, 34, 35, 36, 33, 34...</td>\n",
       "      <td>[57, 204, 205, 206, 20, 33, 34, 35, 36, 33, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "      <td>[128, 289, 26, 42, 57, 204, 290, 68, 291, 292,...</td>\n",
       "      <td>[128, 289, 26, 42, 57, 204, 290, 68, 291, 292,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, there, 's, a, family, where, a, li...</td>\n",
       "      <td>[366, 367, 254, 57, 368, 93, 57, 205, 369, 166...</td>\n",
       "      <td>[366, 367, 254, 57, 368, 93, 57, 205, 369, 166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, 's, ``, love, in, the, time, ...</td>\n",
       "      <td>[417, 418, 254, 227, 419, 51, 4, 292, 3, 420, ...</td>\n",
       "      <td>[417, 418, 254, 227, 419, 51, 4, 292, 3, 420, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [one, of, the, other, reviewers, has, mentione...   \n",
       "1  [a, wonderful, little, production, ., <, br, /...   \n",
       "2  [i, thought, this, was, a, wonderful, way, to,...   \n",
       "3  [basically, there, 's, a, family, where, a, li...   \n",
       "4  [petter, mattei, 's, ``, love, in, the, time, ...   \n",
       "\n",
       "                                             indices  \\\n",
       "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "1  [57, 204, 205, 206, 20, 33, 34, 35, 36, 33, 34...   \n",
       "2  [128, 289, 26, 42, 57, 204, 290, 68, 291, 292,...   \n",
       "3  [366, 367, 254, 57, 368, 93, 57, 205, 369, 166...   \n",
       "4  [417, 418, 254, 227, 419, 51, 4, 292, 3, 420, ...   \n",
       "\n",
       "                                      padded_indices  \n",
       "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
       "1  [57, 204, 205, 206, 20, 33, 34, 35, 36, 33, 34...  \n",
       "2  [128, 289, 26, 42, 57, 204, 290, 68, 291, 292,...  \n",
       "3  [366, 367, 254, 57, 368, 93, 57, 205, 369, 166...  \n",
       "4  [417, 418, 254, 227, 419, 51, 4, 292, 3, 420, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb6e6af9-e49e-4740-9d27-fe96bf233af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16813c1b-6ea4-4f7b-a5cb-b1c86f15cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "       self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # loading the sentences into a tensor\n",
    "        sentence = torch.tensor(self.data.iloc[idx]['padded_indices'], dtype=torch.long)\n",
    "        # loading the labels into a tensor\n",
    "        label = torch.tensor(1 if self.dataset['sentiment'] == 1 else 0, dtype=torch.long)\n",
    "        \n",
    "        return sentence, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bec341-ef37-445d-a902-0c96e3c93c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(df_train)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d04da-5828-4bcf-8a84-9fd5387a5243",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2d200-8a0e-4056-bc69-9367de842cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the CNN model\n",
    "class CNN_Text_Classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
    "        super(CNN_Text_Classifier, self).__init__()\n",
    "\n",
    "        # Embedding layer to map words to vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Convolutional layer: detect patterns in the words\n",
    "        # We take a n-grams approach by making the filter size change so we can detect patterns of the sequence better.\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(3 , embedding_dim))\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(4 , embedding_dim))\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5 , embedding_dim))\n",
    "\n",
    "        # Dropout layers as mentioned in the paper\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Add a channel dimention for the CNN\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x1 = F.relu(self.conv1(x)).squeeze(3)\n",
    "        x2 = F.relu(self.conv1(x)).squeeze(3)\n",
    "        x3 = F.relu(self.conv1(x)).squeeze(3)\n",
    "\n",
    "        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n",
    "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
    "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2) \n",
    "\n",
    "        x = torch.cat((x1, x2, x3), 1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134ce87-f1a9-46ac-b1e7-7f2e55329714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "num_classes = 2\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN_Text_Classifier(vocab_size, embedding_dim, num_classes)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss function: CrossEntropyLoss for multi-class classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: Adam optimizer with a learning rate of 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66d398-a4c4-41d1-8e24-fc13470fb122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0  # Track the total loss for this epoch\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute the output of the model\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass: compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss for the epoch\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78324e6b-6629-4bf3-a03c-092974384c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
